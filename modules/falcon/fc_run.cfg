[General]
stop_all_jobs_on_failure = true
## Set job type
job_type = sge
#job_type = local
#pwatcher_type = blocking
#job_type = string

#skip_checks = true
#use_tmpdir = true
#use_tmpdir = /its1/GB_BT2/jianzuoyi/tmp

# Input data
input_fofn = input.fofn
input_type = raw

#input_fofn = preads.fofn
#input_type = preads

genome_size = 10000
## Correct Pacbio data: overlapping, consensus and pre-assembly
# The length cutoff used for seed reads used for initial mapping
length_cutoff = 500
seed_coverage = 20
# The length cutoff used for seed reads use for pre-assembly
length_cutoff_pr = 500

# fasta2DB splits reads to multiple blocks
# -s50 50Mbp per block, default: 200, daligner need 16G RAM
# -x500 reads will be discarded which length less than 500bp
# -a the second reads come from the ZMW will not be discarded
pa_DBsplit_option =   -a -x5 -s.065536
## daligner perform overlapping analysis against all blocks
# -v show verbose information when daligner is running
# -B4 4 blocks per daligner command process, the bigger this parameter, the less tasks
# -k -w -h related to matched kmer, default: 14, 6, 35
# -T4	Now -T is hard-coded
# -M32 the maxmum RAM per daligner is 32G RAM, this parameter is useful for large genomes
# -t16 filtered the kmer whose coverage is more than 16. default condition: daligner will calculate this value according the -M
# -l1000 ignore the reads whose length is less than 1000bp
# -s1000 the  point is set to 1000 when record the alignment results 
# The daligner's default parameters will be fine for raw pacbio data
# but for corrected pacbio data, the recommanded value are: -k20 -h60 -e.85
pa_HPCdaligner_option =   -v -B4 -t50 -h1 -e.99 -w1 -l1 -s1000 
## Concurrent daligner tasks
da_concurrent_jobs = 25
la_concurrent_jobs = 25

sge_option_da  = -l vf=40G,p=4
sge_option_la  = -l vf=40G,p=4
## FALCON using fc_consensus.py to call consensus according the overlapping results come from daligner
# --min_cov reads will be break or trimed when a region's coverage is less than the threshold value, default: 6
# --min_cov_aln the average coverage of read is less than a threshold, the read will be ignored, default: 10
# --min_n_read, --max_n_read the number of reads must be > min_n_read and < max_n_read, so can call consensus, 
#                            when genome has many repeats, --max_n_read should be reduced,defalut: 10, 500
# --min_idt minimum identity
# --n_core max threads, default: 24
falcon_sense_option = --output_multi --min_idt 0.70 --min_cov 5 --max_n_read 500 --n_core 24
## Concurrent fc_consensus.py tasks
cns_concurrent_jobs = 5

sge_option_fc  = -l vf=64G,p=24
sge_option_cns = -l vf=64G,p=24
#job_queue = bash -C ${CMD} >| ${STDOUT_FILE} 2>| ${STDERR_FILE}
#job_queue = bash -C ${CMD}
# By dropping STD*_FILE, we see all output on the console.
# That helps debugging in TravisCI/Bamboo.
#job_queue = production
#job_queue = sp.q
#job_queue = all.q
#sge_option_da  = -pe smp 8 -q %(job_queue)s
#sge_option_la  = -pe smp 2 -q %(job_queue)s
#sge_option_pda = -pe smp 8 -q %(job_queue)s
#sge_option_pla = -pe smp 2 -q %(job_queue)s
#sge_option_fc  = -pe smp 24 -q %(job_queue)s
#sge_option_cns = -pe smp 8 -q %(job_queue)s

## overlap analysis against preads
ovlp_DBsplit_option = -a -x5 -s50
ovlp_HPCdaligner_option = -v -B4 -t50 -h1 -e.99 -l1 -s1000
#
pda_concurrent_jobs = 25
pla_concurrent_jobs = 25
# 
sge_option_pda = -l vf=20G,p=4
sge_option_pla = -l vf=40G,p=24

LA4Falcon_preload = true

## filtering overlaps
# --bestn 
# --min_cov, --max_cov length_cutoff > 20x preads, --min_cov may be 5 and --max_cov may be 3 multiple average coverage
# --max_diff the difference coverage of two ends, 2 multiple average coverage
# 可以使用在1-preads_ovl目录下运行 fc_ovlp_stats.py --fofn merge-gather/las.fofn 导出overlap结果首尾的覆盖度结果，从而帮助设置以上参数
overlap_filtering_setting = --max_diff 50 --max_cov 75 --min_cov 5 --bestn 10 --n_core 64

#dazcon = 1
